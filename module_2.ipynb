{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 - Frequent pattern mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPM Objectives:\n",
    "1. Find combinations of attributes that are common to many objects\n",
    "2. find significant associations between these combinations\n",
    "3. Find frequent sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions:\n",
    "- $I$ is the set of all items $i_1, ..., i_n$, where $n$ is the number of items\n",
    "- $S \\in I$ is an itemset\n",
    "- $D$ is a set of transactional data\n",
    "- The support of an itemset in D is defined as: $sup_D(S) = \\frac{\\sum_{T \\in D} \\delta(S \\subseteq T)}{|D|}$. It is the ratio between the number of transactions in which the given itemset is present and the total number of transactions. (during the slides, it is not taken as a ratio, but as just the numerator.)\n",
    "- where $\\delta$ is:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta(x)=\n",
    "    \\begin{cases}\n",
    "        1 & \\text{if } x = true\\\\\n",
    "        0 & \\text{if } x = false\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "- The total number of itemsets is $2^{|I|} - 1$\n",
    "- **Frequent Itemset Mining**: Given a set of items $I$, transactional data $D$ and a threshold value $\\sigma$, FIM aims to find those itemsets called \"frequent itemsets\" which are generated from $I$, in which support in T is $\\ge \\sigma$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively computing these frequent itemsets is unfeasible, as the number of producable itemsets grows exponentally with the number of items in $I$. Thankfully, there are multiple ways to limit the search space for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Theorems of Monotonicity\n",
    "\n",
    "1. $sup_D(S) \\ge \\sigma \\Rightarrow \\text{all subsets of } S \\text{ are frequent too}$\n",
    "2. $sup_D(S) \\lt \\sigma \\Rightarrow \\text{all supersets of } S \\text{ are non-frequent too}$\n",
    "\n",
    "Now we'll move on to some algorithms for frequent itemset mining which utilize these theorems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'Mediterranean'}),\n",
       " frozenset({'Arabic'}),\n",
       " frozenset({'Oriental'}),\n",
       " frozenset({'Indian'}),\n",
       " frozenset({'Indian', 'Oriental'}),\n",
       " frozenset({'Mediterranean', 'Oriental'}),\n",
       " frozenset({'Indian', 'Mediterranean'}),\n",
       " frozenset({'Indian', 'Mediterranean', 'Oriental'}),\n",
       " frozenset({'Arabic', 'Mediterranean'})}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Set, Tuple\n",
    "from itertools import product\n",
    "from functools import reduce, partial\n",
    "from operator import or_\n",
    "\n",
    "# Sample transaction data with frozensets\n",
    "t_data = [\n",
    "    ('Andrew', frozenset(['Indian', 'Mediterranean'])),\n",
    "    ('Bernhard', frozenset(['Indian', 'Oriental', 'Fast Food'])),\n",
    "    ('Carolina', frozenset(['Indian', 'Mediterranean', 'Oriental'])),\n",
    "    ('Dennis', frozenset(['Arabic', 'Mediterranean'])),\n",
    "    ('Eve', frozenset(['Oriental'])),\n",
    "    ('Fred', frozenset(['Indian', 'Mediterranean', 'Oriental'])),\n",
    "    ('Gwyneth', frozenset(['Arabic', 'Mediterranean'])),\n",
    "    ('Hayden', frozenset(['Indian', 'Oriental', 'Fast Food'])),\n",
    "    ('Irene', frozenset(['Indian', 'Mediterranean', 'Oriental'])),\n",
    "    ('James', frozenset(['Arabic', 'Mediterranean'])),\n",
    "]\n",
    "\n",
    "# Set of item types\n",
    "all_items = {'Oriental', 'Indian', 'Mediterranean', 'Fast Food', 'Arabic'}\n",
    "\n",
    "# Remove comment in end of line if you want the support normalized\n",
    "def support(t_data: Set[Tuple[str, Set[str]]], item_set: Set[str]):\n",
    "    return len(list(item_set for _,v in t_data if item_set <= v)) # / len(t_data)\n",
    "\n",
    "def apriori(t_data: Set[Tuple[str, Set[str]]], items: Set[str], sigma: float):\n",
    "    \"\"\"Return frequent itemsets for a minimum support threshold sigma\"\"\"\n",
    "    F = {}\n",
    "    C = {}\n",
    "    supD = partial(support, t_data)\n",
    "    k = 1\n",
    "    # Create initial entry for F with sets of single items\n",
    "    F[k] = {frozenset([i]) for i in items if supD(frozenset([i])) >= sigma}\n",
    "    while F[k]:\n",
    "        C[k+1] = generate_candidates(F[k], k + 1)\n",
    "        F[k+1] = {X for X in C[k+1] if supD(X) >= sigma}\n",
    "        k += 1\n",
    "    return reduce(or_, list(F.values()), set())\n",
    "\n",
    "def generate_candidates(F: Set[Set[str]], k: int):\n",
    "    \"\"\"Create new itemsets which will be supersets of the elements\n",
    "    in the last phase of k. Only union if result is of length k\"\"\"\n",
    "    C = {X | Y for X,Y in product(F, F) if len(X | Y) == k}\n",
    "    return C\n",
    "    # Whatever the fuck this is\n",
    "    # return {X for X in C if all(len(Y) == k - 1 for Y in X)}\n",
    "\n",
    "apriori(t_data, all_items, 3) # You get same supported elements as the lattice in page 10 of the lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eclat\n",
    "\n",
    "Instead of storing items in the previous format, eclat stores them in a vertical one, so that checking the support for an itemset of , e.g. cardinality 2, once you have this data format simply becomes a task of finding the cardinality of the intersection between the 2 TID-sets of the items of the itemset.\n",
    "\n",
    "| Item          | TID-set                              | Cardinality |\n",
    "| ------------- | ------------------------------------ | ----------- |\n",
    "| Arabic        | {Dennis, Gwyneth, James}              | 3           |\n",
    "| Indian        | {Andrew, Bernhard, Carolina, Fred, Hayden, Irene} | 6           |\n",
    "| Mediterranean | {Andrew, Carolina, Dennis, Fred, Gwyneth, Irene, James} | 7           |\n",
    "| Oriental      | {Bernhard, Carolina, Eve, Fred, Hayden, Irene} | 6           |\n",
    "| Fast Food     | {Bernhard, Hayden}                    | 2           |\n",
    "\n",
    "So support for $\\{I, M\\}$ (im referring to items by their first letter) is $|\\{Andrew, Bernhard, Carolina, Fred, Hayden, Irene\\}\\cap\\{Andrew, Carolina, Dennis, Fred, Gwyneth, Irene, James\\}|$, which is 4. It works similarly to Apriori, in the sense that it starts with cardinality k = 1, and then iteratively increases k and performs intersections on TID-sets in order to check for support, and if the support for a combination is good, it keeps it, if not, it drops it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
