{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction - Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instances and Labels\n",
    "Instances are presented by their attributes\n",
    "$$\n",
    "{\\bf x}=(x_{1},..., x_{k})\\in{\\mathcal{X}}, \\mathcal{X} = \\mathcal{X}\\times\\cdot\\cdot\\times\\mathcal{X}\n",
    "$$\n",
    "\n",
    "An instance can have a class or a value. An instance whose class/value is known is called **labeled**. Labels in our math notation are portrayed by the $\\mathcal{L}$ set.\n",
    "$$\n",
    "(x,y) \\in{\\mathcal{X}\\times\\mathcal{L}}\n",
    "$$\n",
    "\n",
    "Assume that labels are assigned according to some unknown pattern called a labeling function, which is a mapping from an instance to a label.\n",
    "\n",
    "$$\n",
    "l:\\mathcal{X} \\rightarrow \\mathcal{L}, l(x) = y\n",
    "$$\n",
    "\n",
    "- if $\\mathcal{L} \\subset \\mathbb{Z}^1$ then $l$ is a classification function.\n",
    "- if $\\mathcal{L} \\subset \\mathbb{R}$ then $l$ is a regression function.\n",
    "\n",
    "The problem is that this labeling function is unknown. But even though it is not known, we have observed a sample of instances with their labels. This set of instances is called a training sample.\n",
    "\n",
    "$$\n",
    "\\mathcal{S}^{tr} = \\{(x,y)|x \\in\\mathcal{X}, y \\in\\mathcal{L}\\}\n",
    "$$\n",
    "\n",
    "The solution is to model a function $m: \\mathcal{X} \\rightarrow \\mathcal{L}, m(x) = \\hat{y}$ which is as close to $l$ as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating $l$\n",
    "\n",
    "In the slides, the example of a linear regression model is taken. \n",
    "\n",
    "In this case, $m$ is defined by its type (by type we refer to the x parameter of the function) and parameters $\\Theta$.\n",
    "\n",
    "$$\n",
    "    m^\\Theta(x = (x_1,...,x_k)) = \\Theta_0 + \\Theta_1x_1 + ... + \\Theta_kx_k\n",
    "$$\n",
    "\n",
    "Where k is the number of attributes the instance x has, and $\\Theta$ is defined as:\n",
    "\n",
    "$$\n",
    "    \\Theta = (\\Theta_0, \\Theta_1, ..., \\Theta_k)\n",
    "$$\n",
    "\n",
    "In order to measure if $m$ approximates $l$ well, the example of an empirical error is given.\n",
    "\n",
    "There is also a regression loss function called $l_{r}$, but this is just the squared loss.\n",
    "\n",
    "$$\n",
    "l_r(y, m^\\Theta(x)) = (y - m^\\Theta(x))^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "e r r(m^{\\Theta},{\\cal S}^{t r})=\\sum_{({\\bf x},y)\\in{\\cal S}^{t r}}l_{r}(y,m^{\\Theta}({\\bf x}))=\\sum_{({\\bf x},y)\\in{\\cal S}^{t r}}(y-m^{\\Theta}({\\bf x}))^{2}\n",
    "$$\n",
    "\n",
    "This error function is the sum if the regression losses $l_{r}(y,m^{\\Theta}({\\bf x}))$ for each pair $(x,y)$\n",
    "\n",
    "Let's take a concrete example (basic linear regression, with $\\Theta_0$ representing the bias/y-intercept, and $\\Theta_1$ representing the direction/slope):\n",
    "\n",
    "$$\n",
    "    m^\\Theta(x = (x_1)) = \\Theta_0 + \\Theta_1x_1\n",
    "$$\n",
    "\n",
    "$m$ approximates $l$ with an error, in the slides the error was stochastic, meaning that the error is random and in our case, is part of a random distribution centered at 0 with a standard deviation of $\\sigma^2$.\n",
    "\n",
    "$$\n",
    "    y = l(x) = m^\\Theta(x) + \\epsilon, \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "thus the probability of getting the correct approximations $y$ given ${\\bf x}$ is in the normal distribution centered at $\\Theta_1 + \\Theta_1x_1$ with std. dev. $\\sigma^2$\n",
    "\n",
    "$$\n",
    "p(y|{\\bf x}) = \\mathcal{N}(\\Theta_0 + \\Theta_1x_1 , \\sigma^2)\n",
    "$$\n",
    "\n",
    "The likelyhood (probability of getting $S^{tr}$ given $\\Theta$) is:\n",
    "\n",
    "$$\n",
    "L_{S^{t r}}(\\Theta)=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p({\\bf x},y|\\Theta)=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p(y|{\\bf x},\\Theta)p({\\bf x}|\\Theta)\n",
    "$$\n",
    "\n",
    "The likelihood is decomposed into two parts:\n",
    "- $p(y|{\\bf x},\\Theta)$: The probability of observing $y$ given $x$ and the parameters $\\Theta$. This is the probability distribution of $y$ given $x$ under the assumed model.\n",
    "- $p(\\bf{x}|\\Theta)$: The probability of observing $x$ given the parameters $\\Theta$. This part reflects any prior information or assumptions about the distribution of the input data.\n",
    "\n",
    "Modeling means to choose a type of m and to find its parameters $\\Theta$\n",
    "such that $L_{S^{t r}}(\\Theta)$ is maximal.\n",
    "\n",
    "$$\n",
    "\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p({\\bf x},y)=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p(y|{\\bf x})p({\\bf x})=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p(y|{\\bf x})\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p({\\bf x})\n",
    "$$\n",
    "\n",
    "Since $p(x)$ does not depend on $\\Theta$, it's enough to minimize the conditional likelihood.\n",
    "\n",
    "$$\n",
    "L_{S t r}^{c o n d}(\\Theta)=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}p(y|{\\bf x})=\\prod_{({\\bf x},y)\\in{\\cal S}^{t r}}\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-m^{\\Theta}({\\bf x}))^{2}}{2\\sigma^{2}}}\n",
    "$$\n",
    "\n",
    "Maximizing the formula above is the same as maximizing the conditional log-likelihood. This is true because the log function is monotonic, and it does not change the location of the maximum of the function. It is also more computationally efficient for computers to use the log-likelihood, as it simplifies all the multiplications to additions, which prevents underflow.\n",
    "\n",
    "$$\n",
    "l n L_{S^{t r}}^{c o n d}(\\Theta)=\\sum_{({\\bf x},y)\\in{\\cal S}^{t r}}l n\\Bigl({\\frac{1}{\\sqrt{2\\pi}\\sigma}}e^{-{\\frac{(y-m^{\\Theta}({\\bf x}))^{2}}{2\\sigma^{2}}}}\\Bigr)\\propto\\operatorname*{min}_{({\\bf x},y)\\in{\\cal S}^{t r}}(y-m^{\\Theta}({\\bf x}))^{2}\n",
    "$$\n",
    "\n",
    "The logarithm of the conditional likelihood is proportional to this minimum squared error term. This proportionality suggests that, under certain assumptions and conditions (such as the Gaussian distribution assumption in the likelihood), maximizing the log-likelihood is related to minimizing the squared error. This connection is often used in the context of maximum likelihood estimation and linear regression, where minimizing the squared error is equivalent to maximizing the likelihood of the observed data given the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent optimization\n",
    "\n",
    "for more variables closed form solutions are bothersome\n",
    "- How to find a minimum of an “objective” (i think he means cost/loss function by this) function $f(\\Theta)$?\n",
    "- assume $f$ is differentiable and convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Iterable, Optional\n",
    "from itertools import repeat\n",
    "import numpy as np \n",
    "from numpy.typing import NDArray\n",
    "\n",
    "class StoppingCriteria:\n",
    "    \"\"\"\n",
    "    Gradient descent stopping criteria class\n",
    "    \"\"\"\n",
    "    minimum_delta: Optional[float] # epsilon in the slides, mininum rate of change between old and new weights to continue iteration \n",
    "    n_iter: Optional[int] # Maximum number of iterations\n",
    "\n",
    "    def __init__(self, minimum_delta, n_iter) -> None:\n",
    "        if not minimum_delta and not n_iter:\n",
    "            raise ValueError(\"One or both of minimum_delta or num_iter must be supplied as parameters\")\n",
    "        self.minimum_delta = minimum_delta\n",
    "        self.n_iter = n_iter        \n",
    "\n",
    "def gradient_descent(\n",
    "        gradient: Callable[[NDArray[np.float64], NDArray[np.float64], NDArray[np.float64]], NDArray]\n",
    "      , x: NDArray[np.float64]\n",
    "      , y: NDArray[np.float64]\n",
    "      , start: NDArray[np.float64]\n",
    "      , learn_rate: float\n",
    "      , stop_criteria: StoppingCriteria\n",
    "      ):\n",
    "    \"\"\"\n",
    "    1. gradient: is the function or any Python callable object which accepts the inputs\n",
    "       , the outputs and the weights of a functions and returns the gradient of the function you're trying to minimize.\n",
    "    2. x: The inputs of the linear regression problem\n",
    "    3. y: The outputs corresponding to the elements of the x array\n",
    "    4. start: is the point where the algorithm starts its search, given as an NDArray. This is the Theta in the \n",
    "              slides that he said to initialize not with zeros\n",
    "    5. learn_rate: is the learning rate that controls the magnitude of the vector update.\n",
    "    6. stop_criteria: Small object in which the stop criteria are passed. The 2 stop criteria are:\n",
    "                           1. Maximum number of iterations\n",
    "                           2. Minimum amount of change between iterations allowed\n",
    "                      If one of these thresholds is violated, the optimization stops. \n",
    "    \"\"\"\n",
    "    n_iter = stop_criteria.n_iter\n",
    "    minimum_delta = stop_criteria.minimum_delta\n",
    "\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "\n",
    "    vector = start\n",
    "    for _ in range(n_iter) if n_iter else repeat(1): # repeat(1) is used to create an infinite iterator, the value passed to repeat is arbitrary\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector), np.float64)\n",
    "        if np.all(np.abs(diff) <= minimum_delta): # if change is smaller than the minimum allowed change, stop optimizing\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, I'll try minimizing the Sum of Squared Residuals function for an X and Y value I'll choose below, and some starting weights which are picked randomly from 0-1.\n",
    "\n",
    "SSR for a line approximation function $f$ looks like this:\n",
    "\n",
    "$$\n",
    "    SSR(x, y, \\Theta) = \\sum_i(y_i - f(x_i, \\Theta))^2\n",
    "$$\n",
    "\n",
    "And its gradient (we will partially derivate with respect to $\\Theta_0$ and $\\Theta_1$) looks like this: (Sadly the gradient needs to be analytically derived, and im not writing all the steps here)\n",
    "\n",
    "$$\n",
    "    \\bigtriangledown{}SSR = \\begin{bmatrix} \n",
    "                                mean(\\Theta_0 + \\Theta_1x_i - y_i)\\\\\n",
    "                                mean((\\Theta_0 + \\Theta_1x_i - y_i)x_i)\n",
    "                            \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.62822349, 0.54012867])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ssr_gradient(x: NDArray, y: NDArray, b: NDArray):\n",
    "    res = b[0] + b[1] * x - y\n",
    "    return np.array([res.mean(), (res * x).mean()])\n",
    "\n",
    "x = np.array([5, 15, 25, 35, 45, 55])\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\n",
    "\n",
    "gradient_descent(ssr_gradient, x, y, start=np.array([0.5, 0.5], dtype=np.float64)\n",
    "                 , learn_rate=0.0008, stop_criteria=StoppingCriteria(1e-06, 100_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the points described in x and y, the best weights for our hyperparameters were the ones displayed in the output of the cell above.\n",
    "\n",
    "## Stochastic gradient descent\n",
    "\n",
    "Stochastic gradient descent algorithms are a modification of gradient descent. In stochastic gradient descent, you calculate the gradient using just a random small part of the observations instead of all of them. In some cases, this approach can reduce computation time.\n",
    "\n",
    "Batch stochastic gradient descent is somewhere between ordinary gradient descent and the online method. The gradients are calculated and the decision variables are updated iteratively with subsets of all observations, called minibatches. This variant is very popular for training neural networks.\n",
    "\n",
    "If you were to write an sgd() function, it would be very similar to gradient_descent() but it would use randomly selected minibatches to move along the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "The aim is not to describe the data but rather to predict labels on yet\n",
    "unseen instances.\n",
    "\n",
    "Regression generalization error:\n",
    "\n",
    "$$\n",
    "e r r(m^{\\Theta})=E_{({\\bf x},y)}\\{l_{r}(y,m^{\\Theta}({\\bf x}))\\}=\\int\\limits_\\mathcal{X}\\int\\limits_\\mathcal{L} l_{r}(y,m^{\\Theta}({\\bf x}))p({\\bf x},y)\\,\\mathrm{d}y\\mathrm{d}{\\bf x}\n",
    "$$\n",
    "\n",
    "In simpler terms, the generalization error is calculated by taking the average (expected value) of the loss function over all possible pairs of input-output $({\\bf x},y)$ according to the underlying probability distribution $p({\\bf x},y)$.\n",
    "\n",
    "Classification generalization error:\n",
    "\n",
    "$$\n",
    "e r r(m^{\\Theta})=E_{({\\bf x},y)}\\{l_{r}(y,m^{\\Theta}({\\bf x}))\\}=\\int\\limits_\\mathcal{X} \\sum_{c \\in \\mathcal{L}} l_{c}(y,m^{\\Theta}({\\bf x}))p({\\bf x},y = c)\\,\\mathrm{d}y\\mathrm{d}{\\bf x}\n",
    "$$\n",
    "\n",
    "In simpler terms, this classification error formula is calculating the average (expected value) of the classification loss over all possible pairs of input and true labels, with the additional consideration of multiple classes (summing over $c$). It quantifies how well the model $m^Θ$ classifies input instances into different classes.\n",
    "\n",
    "This type of error calculation is common in classification problems where the output $y$ represents a class label, and $lc$​ is a loss function specific to classification, such as cross-entropy loss.\n",
    "\n",
    "Bayes predictor minimizes the generalization error:\n",
    "$$\n",
    "    m_B = \\arg \\min err(m^\\Theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "The aim is to achieve low generalization error of the model\n",
    "- it means, describe the available data (training data) as well as possible\n",
    "- but also, don’t fit the model to the noise in the data\n",
    "- i.e. try to get a smooth model\n",
    "\n",
    "Regularized linear regression objective function:\n",
    "\n",
    "$$\n",
    "f(\\Theta) = \\sum_{({\\bf x},y) \\in \\mathcal{S}^{tr}} (t - m^\\Theta(x))^2 + \\lambda ||\\Theta||^2\n",
    "$$\n",
    "\n",
    "Where $\\sum_{({\\bf x},y) \\in \\mathcal{S}^{tr}} (t - m^\\Theta(x))^2$ is the empirical error and  $\\lambda ||\\Theta||^2$ is the regularization term.\n",
    "\n",
    "Quiz question: Write down the objective function for regularized linear regression and indicate what are its hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "According to $\\Theta$, we can have many different models $m^\\Theta$, and each model can be trained with many different training samples. But which ones to choose, and how do we choose them?\n",
    "\n",
    "There are 2 main metrics:\n",
    "- Bias: Measures how $m^{\\Theta,\\mathcal{S^{tr_2}}}, m^{\\Theta,\\mathcal{S^{tr_2}}}, ... ,m^{\\Theta,\\mathcal{S^{tr_m}}}$ differs from $l$ and determines how generic the model $m^\\Theta$ is.\n",
    "$$\n",
    "    bias_{m^\\Theta}^2({\\bf x}) = (l({\\bf x}) - {\\bf E}_{\\mathcal{S}^{tr}}\\{m^{\\Theta,\\mathcal{S}^{tr}}\\})^2\n",
    "$$\n",
    "- Variance: Measures how $m^{\\Theta,\\mathcal{S^{tr_2}}}, m^{\\Theta,\\mathcal{S^{tr_2}}}, ... ,m^{\\Theta,\\mathcal{S^{tr_m}}}$ differs from each other and determines how stable the model $m^\\Theta$ is.\n",
    "$$\n",
    "v a r i a n c e_{m^\\Theta}({\\bf x})={\\bf E}_{S^{t r}}\\{~(\\,m^{\\Theta,S^{t r}}({\\bf x})-{\\bf E}_{S^{t r}}\\{m^{\\Theta,S^{t r}}({\\bf x})\\}\\,)^{2}\\}\n",
    "$$\n",
    "\n",
    "Underfitting: Low variance, high bias. Means the model is too general\n",
    "\n",
    "Overfitting: Low bias, high variance. Means the model is too specific\n",
    "\n",
    "Usually, the bias decreases with the complexity of the model, while\n",
    "variance increases with the complexity of the model. Thus, we need to\n",
    "find a tradeoff model, which is not too general nor too specific.\n",
    "\n",
    "# What happens if we sum up the bias and the variance?\n",
    "\n",
    "From now on we will denote $m^\\Theta$ as $\\hat{y}$\n",
    "\n",
    "$$\n",
    "bias_{m^\\Theta}^2(x) + variance_{m^\\Theta}(x) = {\\bf E}\\{(l(x) - \\hat{y})^2\\}\n",
    "$$\n",
    "\n",
    "We get the expected squared error of the model over all training\n",
    "samples w.r.t. the labeling.\n",
    "\n",
    "## Noise in sampling\n",
    "\n",
    "$$\n",
    "noise({\\bf x}) =  {\\bf E}_{({\\bf x}, y)}\\{(y - l(x))^2\\}\n",
    "$$\n",
    "\n",
    "Usually, we assume a normally distributed sampling error $\\epsilon \\sim \\mathcal{N}(0, 1)$, thus:\n",
    "$$\n",
    "{\\bf E}_{({\\bf x},y)}\\{y\\} = l(x)\n",
    "$$\n",
    "\n",
    "Now if we sum up the bias, variance and noise we get:\n",
    "$$\n",
    "bias_{m^\\Theta}^2(x) + variance_{m^\\Theta}(x) + noise({\\bf x})\n",
    "$$\n",
    "$$\n",
    "{\\bf E}_{S^{tr}}\\{(l(x) - \\hat{y})^2\\} + noise({\\bf x}) = {\\bf E}_{S^{tr}}\\{{\\bf E}_{({\\bf x}, y)}\\{(y - \\hat{y})^2\\}\\}\n",
    "$$\n",
    "\n",
    "We get the expected squared error of the model over all training\n",
    "samples and all instances w.r.t. the observed labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set, RMSE and MAE\n",
    "\n",
    "Test set: $S^{te} \\subset \\mathcal{X} \\times \\mathcal{L} \\setminus \\mathcal{S}^{tr}$\n",
    "\n",
    "Root mean square error (regression):\n",
    "\n",
    "$$\n",
    "rmse(m^{\\Theta,S^{t r}}({\\bf x}),S^{t e})=\\sqrt{\\frac{\\sum_{({\\bf x},y)\\in S^{t e}}(m^{\\Theta,S^{t r}}({\\bf x})-y)^{2}}{|{\\mathcal{S}}^{t e}|}}\n",
    "$$\n",
    "\n",
    "Mean absolute error (classification)\n",
    "\n",
    "$$\n",
    "mae(m^{\\Theta,S^{t r}}({\\bf x}),S^{t e})=\\frac{\\sum_{({\\bf x},y)\\in S^{t e}}I(m^{\\Theta,S^{t r}}({\\bf x}) \\ne y)}{|{\\mathcal{S}}^{t e}|}\n",
    "$$\n",
    "\n",
    "Where $I(\\bullet) = 1$ if condition $(\\bullet)$ holds, else = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross-validation\n",
    "\n",
    "The point of K-fold cross validation is to choose the best hyper-parameters which minimize an error function for a model, by training the model based on splits of the training set.\n",
    "\n",
    "1. Split the training sample $\\mathcal{S}^{tr} = \\bigcup\\limits_{k} \\mathcal{S}_k^{tr}$\n",
    "2. choose those hyper-parameters $\\Xi$ such that: ($\\mathcal{S}^{tr}_i$ is called a validation fold)\n",
    "$$\n",
    "    \\Xi = \\arg \\min \\{\\frac{1}{k}\\sum\\limits_{i=1}^{k}err(m^{\\Theta,\\Xi,\\cup_{i\\le{}j\\le{}k,j\\ne{}i} \\mathcal{S}^{tr}_j})\\}\n",
    "$$\n",
    "3. Re-learn the final $m^\\Theta$ using $\\Xi$ on the whole training set $S^{tr}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Classifier\n",
    "\n",
    "$C_1, ..., C_k$ are mutually exclusive and exhaustive classes.\n",
    "\n",
    "1. Prior probability $P(C_i)$\n",
    "    - Probability that an arbitrary instance is labeled with class $C_i$\n",
    "2. Likelihood $P(x|C_i)$\n",
    "    - Probability that an arbitrary instance of class $C_i$ is associated with the instance $x$\n",
    "3. Evidence $P(x)$\n",
    "    - Probability that the instance $x$ is seen regardless of its class\n",
    "4. Posterior probability $P(C_i|x)$\n",
    "    - Probability that the instance $x$ is labeled with class $C_i$\n",
    "\n",
    "$$\n",
    "    P(C_i | x) = \\frac{P(x | C_i)P(C_i)}{P(c)}\n",
    "$$\n",
    "\n",
    "for $x$ predict $C_i$ for which $P(C_i|x)$ is maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant function\n",
    "\n",
    "in case of K classes, classification can be seen as an implementation of\n",
    "K discriminant functions g1(x), . . . , gK (x) such that\n",
    "- for x predict Ci for which gi(x) is maximal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "The model for logistic regression is defined as:\n",
    "\n",
    "$$\n",
    " P(C = 1 | {\\bf x}) = s({\\bf w}^T{\\bf x} + w_0) + \\epsilon = \\frac{1}{1 + e^{-({\\bf w}^T{\\bf x} + w_0)}} + \\epsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "s(t) = \\frac{1}{1+e^{-t}}\n",
    "$$\n",
    "\n",
    "Where the function $s(t)$ is called the sigmoid logistic function and $\\bf{w}$ and $w_0$ are model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
